# 多模态智能 Agent 系统

基于 **Qwen 2.5-VL** 多模态大模型的智能问答与对话系统，支持文本+图像+文档输入，具备图文联合推理与知识检索增强（RAG）能力。

## ✨ 特性

- 🖼️ **多模态理解**: 支持图片上传和图文联合推理
- � **文档知识库**: 支持上传PDF/TXT文件，自动解析并添加到知识库
- �🔧 **工具调用**: 集成计算器、知识检索、天气查询等工具
- 📚 **RAG增强**: 基于 Chroma 向量数据库的检索增强生成
- 🧠 **LangGraph ReAct**: 使用ReAct工作流（思考-行动-观察）
- 💬 **智能对话**: 支持多轮对话和上下文理解
- 🚀 **工程化部署**: FastAPI 后端 + Streamlit 前端

---

## 📚 什么是RAG（知识库功能）？

**RAG (Retrieval-Augmented Generation)** 是检索增强生成技术：

```
┌─────────────────────────────────────────────────────────────┐
│                         RAG 工作流程                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1️⃣ 上传文档           2️⃣ 向量化存储          3️⃣ 智能检索   │
│  ┌──────────┐         ┌──────────┐         ┌──────────┐    │
│  │ PDF/TXT  │ ──────> │ 文本分块 │ ──────> │ Chroma   │    │
│  │ 文献资料 │         │ 向量化   │         │ 向量库   │    │
│  └──────────┘         └──────────┘         └──────────┘    │
│                                                   │         │
│  4️⃣ 输入问题 ─────────> 5️⃣ 检索相关内容 <────────┘         │
│       │                       │                             │
│       └──────> 6️⃣ 结合知识生成回答 <─────┘                  │
│                       │                                     │
│                       v                                     │
│             📝 带有知识依据的精确回答                         │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### � 典型应用场景

**场景**: 你下载了一篇关于"气候变化"的PDF论文，拍摄了一张冰川融化的图片。

1. **上传论文**: 在侧边栏"📄 文档上传"选择PDF文件 → 点击"上传到知识库"
2. **上传图片**: 在侧边栏"📷 图片上传"选择冰川图片
3. **提问**: "请根据论文内容，解释这张图片中冰川融化的原因"
4. **结果**: Agent会检索论文中的相关段落，结合图片分析，生成专业的解答

### 📦 "上传到知识库"是什么意思？

**知识库** 就像是Agent的"记忆"或"参考资料库"：

| 操作 | 说明 |
|------|------|
| 上传文档 | 将PDF/TXT文件内容提取出来 |
| 文本分块 | 将长文档切分成小段落（约500字一块） |
| 向量化 | 使用AI模型将文本转换为数字向量 |
| 存储到Chroma | 保存到本地向量数据库中 |
| 后续检索 | 当你提问时，Agent自动搜索相关内容 |

> 💡 上传的文档**不会消失**，会持续保存在知识库中供后续对话使用。

---

## �🏗️ 系统架构

```
┌─────────────────────────────────────────────────────────────┐
│                    Streamlit Frontend                        │
│  ┌──────────┐  ┌──────────────┐  ┌───────────────────────┐  │
│  │ 文档上传  │  │   图片上传   │  │      对话界面        │  │
│  │ PDF/TXT  │  │   PNG/JPG   │  │                       │  │
│  └──────────┘  └──────────────┘  └───────────────────────┘  │
└─────────────────────────┬───────────────────────────────────┘
                          │ HTTP API
┌─────────────────────────▼───────────────────────────────────┐
│                    FastAPI Backend                           │
│  ┌──────────────┐  ┌──────────────┐  ┌─────────────────┐    │
│  │ LangGraph    │  │ Qwen 2.5-VL  │  │ Chroma Vector   │    │
│  │ ReAct Agent  │  │ Service      │  │ Service         │    │
│  └──────────────┘  └──────────────┘  └─────────────────┘    │
│  ┌──────────────────────────────────────────────────────┐   │
│  │                   Custom Tools                        │   │
│  │  计算器 │ 知识检索 │ 图像分析 │ 时间查询 │ 天气查询  │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

---

## � 快速开始

### 1. 创建Conda环境（推荐）

```bash
conda create -n multimodal-agent python=3.11 -y
conda activate multimodal-agent
```

### 2. 安装依赖

```bash
cd d:\PY\PYWORK\agents
pip install -r requirements.txt
```

### 3. 配置环境变量

复制 `.env.example` 为 `.env`：

```bash
copy .env.example .env
```

编辑 `.env` 文件，填入API Key：

```env
DASHSCOPE_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

> 💡 获取 API Key: 访问 [阿里云百炼平台](https://dashscope.console.aliyun.com/)

### 4. 使用启动脚本（推荐）

```powershell
.\start.ps1
```

或手动启动：

```bash
# 终端1: 启动后端
uvicorn app.main:app --reload --port 8000

# 终端2: 启动前端
streamlit run streamlit_app/app.py --server.port 8501
```

### 5. 访问应用

- 🌐 前端界面: http://localhost:8501
- 📡 API 文档: http://localhost:8000/docs

---

## 📖 使用指南

### 📄 上传文档到知识库（RAG核心功能）

1. 在左侧边栏找到 **"📄 文档上传"** 区域
2. 点击"Browse files"选择PDF或TXT文件
3. 点击 **"📤 上传到知识库"** 按钮
4. 等待显示"✅ 文档上传成功"
5. 可以看到文件被分成了多少个文本块

**支持的文件格式**: PDF、TXT、MD

### 🖼️ 上传图片进行分析

1. 在左侧边栏找到 **"📷 图片上传"** 区域
2. 选择要分析的图片（建议<5MB）
3. 在对话框中询问关于图片的问题

### 💬 多模态RAG对话（推荐玩法）

**步骤**:
1. 先上传一篇PDF文献到知识库
2. 再上传一张相关的图片
3. 输入: "请根据文献内容，解释这张图片中的现象"

**示例对话**:

| 你的输入 | Agent的能力 |
|---------|------------|
| "请总结上传文档的主要内容" | 检索知识库并总结 |
| "图片中是什么？" | 分析上传的图片 |
| "根据论文，解释图中的现象" | 结合图片+知识库回答 |
| "计算 123 * 456" | 调用计算器工具 |
| "现在几点了？" | 调用时间工具 |

### ⚙️ 功能开关

侧边栏提供两个开关：

| 开关 | 作用 |
|------|------|
| 🔧 启用工具调用 | 允许Agent调用计算器、时间等工具 |
| 📚 启用知识检索 | 允许Agent从知识库检索相关内容 |

---

## 📁 项目结构

```
agents/
├── app/                          # 后端应用
│   ├── main.py                   # FastAPI 主入口
│   ├── config.py                 # 配置管理
│   ├── services/
│   │   ├── agent_service.py      # LangGraph ReAct Agent
│   │   ├── document_service.py   # PDF/TXT 解析服务
│   │   ├── vector_service.py     # Chroma 向量检索
│   │   └── qwen_service.py       # Qwen VL 服务
│   └── tools/
│       └── custom_tools.py       # 自定义工具
├── streamlit_app/                # 前端应用
│   ├── app.py                    # Streamlit 主界面
│   └── components/
│       ├── document_upload.py    # 文档上传组件
│       ├── upload.py             # 图片上传组件
│       └── chat.py               # 对话组件
├── data/
│   ├── knowledge/                # 知识库文档目录
│   └── chroma/                   # 向量数据库存储
├── requirements.txt
├── .env.example
├── start.ps1                     # Windows启动脚本
└── README.md
```

---

## 🔧 API 接口

### POST /chat
智能对话接口

### POST /knowledge/upload
上传文档到知识库（支持PDF/TXT）

### GET /knowledge/stats
获取知识库统计信息

### POST /knowledge/search
搜索知识库

完整API文档: http://localhost:8000/docs

---

## 📝 注意事项

1. **API Key**: 必须配置有效的 DashScope API Key
2. **文件大小**: PDF文件建议不超过10MB，图片不超过5MB
3. **知识库持久化**: 上传的文档会保存在 `data/chroma/` 目录
4. **清空知识库**: 删除 `data/chroma/` 目录后重启服务

---

## 📄 许可证

MIT License
